{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Service - Q&A with semantic answering using LlamaIndex ðŸ¦™ (GPT Index)\n",
    "\n",
    "Firstly, create a file called `.env` in this folder, and add the following content, obviously with your values:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=xxxxxx\n",
    "OPENAI_API_BASE=https://xxxxxxx.openai.azure.com/\n",
    "```\n",
    "\n",
    "Then, let's install all dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask==2.3.3 in /workspaces/azure-LlamaIndex-qna/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 1)) (2.3.3)\n",
      "Requirement already satisfied: python-dotenv==0.21.0 in /workspaces/azure-LlamaIndex-qna/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: openai==0.27.1 in /workspaces/azure-LlamaIndex-qna/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 3)) (0.27.1)\n",
      "Requirement already satisfied: llama-index==0.4.33 in /workspaces/azure-LlamaIndex-qna/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 4)) (0.4.33)\n",
      "Requirement already satisfied: langchain==0.0.129 in /workspaces/azure-LlamaIndex-qna/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 5)) (0.0.129)\n",
      "Requirement already satisfied: azure-identity==1.6.0 in /workspaces/azure-LlamaIndex-qna/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 6)) (1.6.0)\n",
      "Collecting streamlit==1.18.1 (from -r ../requirements.txt (line 7))\n",
      "  Obtaining dependency information for streamlit==1.18.1 from https://files.pythonhosted.org/packages/75/83/aab60f6a6d9317ff546b67803d17027c381aedfbb29b45507784ad77f889/streamlit-1.18.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached streamlit-1.18.1-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy in /workspaces/azure-LlamaIndex-qna/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 8)) (1.26.4)\n",
      "Requirement already satisfied: pandas in /workspaces/azure-LlamaIndex-qna/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 9)) (2.2.3)\n",
      "Collecting matplotlib==3.6.3 (from -r ../requirements.txt (line 10))\n",
      "  Using cached matplotlib-3.6.3.tar.gz (35.9 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting plotly==5.12.0 (from -r ../requirements.txt (line 11))\n",
      "  Obtaining dependency information for plotly==5.12.0 from https://files.pythonhosted.org/packages/37/13/906b97d68e7bc2c67f20a7784d223080df7777680f5bd12a242729c10699/plotly-5.12.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached plotly-5.12.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.55.2 Requires-Python <3.5; 1.10.0 Requires-Python <3.12,>=3.8; 1.10.0rc1 Requires-Python <3.12,>=3.8; 1.10.0rc2 Requires-Python <3.12,>=3.8; 1.10.1 Requires-Python <3.12,>=3.8; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11; 1.9.0 Requires-Python >=3.8,<3.12; 1.9.0rc1 Requires-Python >=3.8,<3.12; 1.9.0rc2 Requires-Python >=3.8,<3.12; 1.9.0rc3 Requires-Python >=3.8,<3.12; 1.9.1 Requires-Python >=3.8,<3.12\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scipy==1.10.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.6.0, 1.6.1, 1.9.2, 1.9.3, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.11.4, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.13.0rc1, 1.13.0, 1.13.1, 1.14.0rc1, 1.14.0rc2, 1.14.0, 1.14.1, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for scipy==1.10.0\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total embedding token usage: 4962 tokens\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from llama_index import GPTSimpleVectorIndex, SimpleDirectoryReader, LLMPredictor, PromptHelper, LangchainEmbedding\n",
    "from langchain.chat_models import AzureChatOpenAI  # Use AzureChatOpenAI for chat-based models\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Load environment variables (set OPENAI_API_KEY and OPENAI_API_BASE in .env)\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Azure OpenAI Service API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\"  # Use the correct API version for chat models\n",
    "openai.api_base = os.getenv('OPENAI_API_BASE')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Use AzureChatOpenAI for chat-based models like gpt-35-turbo or gpt-4\n",
    "# Use AzureChatOpenAI for chat-based models like gpt-35-turbo or gpt-4\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-4o\",  # Ensure deployment_name matches your Azure setup\n",
    "    temperature=0,\n",
    "    openai_api_version=\"2023-03-15-preview\"  # Explicitly specify the API version\n",
    ")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", chunk_size=1)\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "embedding_llm = LangchainEmbedding(embeddings)\n",
    "\n",
    "# Load documents\n",
    "documents = SimpleDirectoryReader('../data/qna/').load_data()\n",
    "\n",
    "# Define prompt helper\n",
    "max_input_size = 3000\n",
    "num_output = 256\n",
    "chunk_size_limit = 1000\n",
    "max_chunk_overlap = 20\n",
    "prompt_helper = PromptHelper(max_input_size=max_input_size, num_output=num_output, max_chunk_overlap=max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    "\n",
    "# Create index\n",
    "index = GPTSimpleVectorIndex(documents, llm_predictor=llm_predictor, embed_model=embedding_llm, prompt_helper=prompt_helper)\n",
    "index.save_to_disk(\"index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 468 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 15 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Cloud-Based AI Service**: Azure OpenAI Service is a cloud service that provides access to OpenAI's advanced language models.\n",
      "- **Powerful Language Models**: Offers state-of-the-art models like GPT-4 for AI capabilities.\n",
      "- **Wide Range of Applications**: Can be used for tasks such as natural language processing, text generation, question answering, content summarization, code generation, and more.\n",
      "- **Enterprise-Grade Security**: Ensures secure and compliant infrastructure for businesses.\n",
      "- **Azure Integration**: Can integrate seamlessly with other Azure services.\n",
      "- **Scalability and Reliability**: Provides scalable and reliable performance for AI applications.\n",
      "- **Usage Requirements**:\n",
      "  - Requires an Azure subscription.\n",
      "  - Requires access to Azure OpenAI Service.\n",
      "  - Needs API keys and an endpoint URL.\n",
      "  - Requires a deployed model instance.\n",
      "- **Flexible Integration**: Supports multiple programming languages and can be integrated into applications via REST APIs or SDKs.\n"
     ]
    }
   ],
   "source": [
    "response = index.query(\"What is azure openai service? give me back a bullet point list\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
